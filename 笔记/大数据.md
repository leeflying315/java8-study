# ODS设计

人们对数据的处理行为可以划分为操作型数据处理和分析型数据处理，操作型数据处理一般放在传统的**数据库**(`Database,DB`)中进行，分析型数据处理则需要在**数据仓库**(`Data Warehouse,DW`)中进行。但是并不是所有的数据处理都可以这样划分，换句话说，人们对数据的处理需求并不只有这两类，比如，有些操作型处理并不适合放在传统的数据库上完成，也有些分析型处理不适合在数据仓库中进行。这时候就需要第三种数据存储体系，**操作数据存储**(`Operational Data Store,ODS`)系统就因此产生。它的出现，也将`DB~DW`两层数据架构转变成`DB~ODS~DW`三层数据架构。

> **那么，什么是ODS?**
> ODS是用于支持企业日常的、全局应用的数据集合。

ODS中的数据具有以下4个基本特征：
① **面向主题的：**进入ODS的数据是来源于各个操作型数据库以及其他外部数据源，数据进入ODS前必须经过 `ETL`过程（抽取、清洗、转换、加载等）。
② **集成的：**ODS的数据来源于各个操作型数据库，同时也会在数据清理加工后进行一定程度的综合。
③ **可更新的：**可以联机修改。这一点区别于数据仓库。
④ **当前或接近当前的：**“当前”是指数据在存取时刻是最新的，“接近当前”是指存取的数据是最近一段时间得到的。
ODS是这样一种数据存储系统，它将来自不同数据源的数据（各种操作型数据库、外部数据源等）通过ETL过程汇聚整合成面向主题的、集成的、企业全局的、一致的数据集合（主要是最新的或者最近的细节数据以及可能需要的汇总数据），用于满足企业准实时的OLAP操作和企业全局的OLTP操作，并为数据仓库提供集成后的数据，将数据仓库系统中的ETL过程下沉到ODS中完成以减轻数据仓库的压力。

an ODS contains small amounts of information that is updated through the course of business transactions. An ODS will perform numerous quick and simple [queries](https://www.webopedia.com/TERM/Q/query.html) on small amounts of data, such as acquiring an account balance or finding the status of a customer order, whereas a data warehouse will perform complex queries on large amounts of data. An ODS contains only current operational data while a data warehouse contains both current and historical data.

# Kafka

![Kafka模型](F:\workspace\java8-study\笔记\pic\Kafka模型.jpg)

## Kafka rebalance 机制

**发生 rebalance 的时机**

1. 组成员个数发生变化。例如有新的 `consumer` 实例加入该消费组或者离开组。
2. 订阅的 `Topic` 个数发生变化。
3. 订阅 `Topic` 的分区数发生变化。

**Kafka性能秘诀**

Kafka在磁盘上只做Sequence I/O。

- Sequence I/O: 600MB/s
- Random I/O: 100KB/s

Kafka重度依赖底层操作系统提供的PageCache功能

传统的网络I/O操作流程，大体上分为以下4步：

1. OS 从硬盘把数据读到内核区的PageCache。
2. 用户进程把数据从内核区Copy到用户区。
3. 然后用户进程再把数据写入到Socket，数据流入内核区的Socket Buffer上。
4. OS 再把数据从Buffer中Copy到网卡的Buffer上，这样完成一次发送。

![](F:\workspace\java8-study\笔记\pic\传统IO.jpg)

整个过程共经历两次Context Switch，四次System Call。同一份数据在内核Buffer与用户Buffer之间重复拷贝，效率低下。其中2、3两步没有必要，完全可以直接在内核区完成数据拷贝。这也正是Sendfile所解决的问题，经过Sendfile优化后，整个I/O过程就变成了下面这个样子。

![](F:\workspace\java8-study\笔记\pic\零拷贝技术.jpg)

**消费者进程挂掉的情况**

1. `session` 过期
2. `heartbeat` 过期

`Rebalance` 发生时，`Group` 下所有 `Consumer` 实例都会协调在一起共同参与，`Kafka` 能够保证尽量达到最公平的分配。但是 `Rebalance` 过程对 `Consumer Group` 会造成比较严重的影响。在 `Rebalance` 的过程中 `Consumer Group` 下的所有消费者实例都会停止工作，等待 `Rebalance` 过程完成。

## Kafka中ZK的作用

Kafka使用ZooKeeper存放集群元数据、成员管理、Controller选举，以及其他一些管理类任务。之后，等KIP-500提案完成后，Kafka将完全不再依赖于ZooKeeper。

- “存放元数据”是指主题分区的所有数据都保存在 ZooKeeper 中，且以它保存的数据为权威，其他 “人” 都要与它保持对齐。
- “成员管理” 是指 Broker 节点的注册、注销以及属性变更，等等。
- “Controller 选举” 是指选举集群 Controller，而其他管理类任务包括但不限于主题删除、参数配置等。

## Kafka 零拷贝

在Kafka中，体现Zero Copy使用场景的地方有两处：基于mmap的索引和日志文件读写所用的TransportLayer。

- 索引都是基于MappedByteBuffer的，也就是让用户态和内核态共享内核态的数据缓冲区，此时，数据不需要复制到用户态空间。不过，mmap虽然避免了不必要的拷贝，但不一定就能保证很高的性能。在不同的操作系统下，mmap的创建和销毁成本可能是不一样的。很高的创建和销毁开销会抵消Zero Copy带来的性能优势。由于这种不确定性，在Kafka中，只有索引应用了mmap，最核心的日志并未使用mmap机制。
- TransportLayer是Kafka传输层的接口。它的某个实现类使用了FileChannel的transferTo方法。该方法底层使用sendfile实现了Zero Copy。对Kafka而言，如果I/O通道使用普通的PLAINTEXT，那么，Kafka就可以利用Zero Copy特性，直接将页缓存中的数据发送到网卡的Buffer中，避免中间的多次拷贝。相反，如果I/O通道启用了SSL，那么，Kafka便无法利用Zero Copy特性了。

## Kafka消费单线程

Java Consumer是双线程的设计。一个线程是用户主线程，负责获取消息；另一个线程是心跳线程，负责向Kafka汇报消费者存活情况。将心跳单独放入专属的线程，能够有效地规避因消息处理速度慢而被视为下线的“假死”情况。

单线程获取消息的设计能够避免阻塞式的消息获取方式。单线程轮询方式容易实现异步非阻塞式，这样便于将消费者扩展成支持实时流处理的操作算子。因为很多实时流处理操作算子都不能是阻塞式的。另外一个可能的好处是，可以简化代码的开发。多线程交互的代码是非常容易出错的。

## 简述Follower副本消息同步的完整流程

首先，Follower发送FETCH请求给Leader。

接着，Leader会读取底层日志文件中的消息数据，再更新它内存中的Follower副本的LEO值，更新为FETCH请求中的fetchOffset值。

最后，尝试更新分区高水位值。Follower接收到FETCH响应之后，会把消息写入到底层日志，接着更新LEO和HW值。

Leader和Follower的HW值更新时机是不同的，Follower的HW更新永远落后于Leader的HW。这种时间上的错配是造成各种不一致的原因。

因此，对于消费者而言，消费到的消息永远是所有副本中最小的那个HW。



- LEO（Log End Offset）：日志末端位移值或末端偏移量，表示日志下一条待插入消息的位移值。举个例子，如果日志有10条消息，位移值从0开始，那么，第10条消息的位移值就是9。此时，LEO = 10。
- LSO（Log Stable Offset）：这是Kafka事务的概念。如果你没有使用到事务，那么这个值不存在（其实也不是不存在，只是设置成一个无意义的值）。该值控制了事务型消费者能够看到的消息范围。它经常与Log Start Offset，即日志起始位移值相混淆，因为有些人将后者缩写成LSO，这是不对的。在Kafka中，LSO就是指代Log Stable Offset。
- AR（Assigned Replicas）：AR是主题被创建后，分区创建时被分配的副本集合，副本个数由副本因子决定。
- ISR（In-Sync Replicas）：Kafka中特别重要的概念，指代的是AR中那些与Leader保持同步的副本集合。在AR中的副本可能不在ISR中，但Leader副本天然就包含在ISR中。
- HW（High watermark）：高水位值，这是控制消费者可读取消息范围的重要字段。一个普通消费者只能“看到”Leader副本上介于Log Start Offset和HW（不含）之间的所有消息。水位以上的消息是对消费者不可见的。

需要注意的是，通常在ISR中，可能会有人问到为什么有时候副本不在ISR中，这其实也就是上面说的Leader和Follower不同步的情况，为什么我们前面说，短暂的不同步我们可以关注，但是长时间的不同步，我们需要介入排查了，因为ISR里的副本后面都是通过replica.lag.time.max.ms，即Follower副本的LEO落后Leader LEO的时间是否超过阈值来决定副本是否在ISR内部的

# ClickHouse

MergeTree、ReplacingMergeTree、CollapsingMergeTree、VersionedCollapsingMergeTree、SummingMergeTree、AggregatingMergeTree引擎。

### MergeTree

MergeTree虽然有主键索引，但是其主要作用是加速查询，而不是类似MySQL等数据库用来保持记录唯一。即便在Compaction完成后，主键相同的数据行也仍旧共同存在。

### ReplacingMergeTree

ReplacingMergeTree可以对主键去重，但是存在缺点：

- **在没有彻底optimize之前，可能无法达到主键去重的效果，比如部分数据已经被去重，而另外一部分数据仍旧有主键重复**；
- **在分布式场景下，相同primary key的数据可能被sharding到不同节点上，不同shard间可能无法去重**；
- optimize是后台动作，无法预测具体执行时间点；
- 手动执行optimize在海量数据场景下要消耗大量时间，无法满足业务即时查询的需求；

因此ReplacingMergeTree更多被用于确保数据最终被去重，而无法保证查询过程中主键不重复。

### CollapsingMergeTree

ClickHouse实现了CollapsingMergeTree来消除ReplacingMergeTree的限制。该引擎要求在建表语句中指定一个标记列Sign，后台Compaction时会将主键相同、Sign相反的行进行折叠，也即删除。

CollapsingMergeTree将行按照Sign的值分为两类：Sign=1的行称之为状态行，Sign=-1的行称之为取消行。

每次需要新增状态时，写入一行状态行；需要删除状态时，则写入一行取消行。

在后台Compaction时，状态行与取消行会自动做折叠（删除）处理。而尚未进行Compaction的数据，状态行与取消行同时存在。

因此为了能够达到主键折叠（删除）的目的，需要业务层进行适当改造：

1） 执行删除操作需要写入取消行，而取消行中需要包含与原始状态行一样的数据（Sign列除外）。所以在应用层需要记录原始状态行的值，或者在执行删除操作前先查询数据库获取原始状态行；

2）由于后台Compaction时机无法预测，在发起查询时，状态行和取消行可能尚未被折叠；另外，ClickHouse无法保证primary key相同的行落在同一个节点上，不在同一节点上的数据无法折叠。因此在进行count(*)、sum(col)等聚合计算时，可能会存在数据冗余的情况。为了获得正确结果，业务层需要改写SQL，将`count()、sum(col)`分别改写为`sum(Sign)、sum(col * Sign)`。

CollapsingMergeTree虽然解决了主键相同的数据即时删除的问题，但是状态持续变化且多线程并行写入情况下，状态行与取消行位置可能乱序，导致无法正常折叠。

### VersionedCollapsingMergeTree

VersionedCollapsingMergeTree表引擎在建表语句中新增了一列Version，用于在乱序情况下记录状态行与取消行的对应关系。主键相同，且Version相同、Sign相反的行，在Compaction时会被删除。

### SummingMergeTree

ClickHouse通过SummingMergeTree来支持对主键列进行预先聚合。在后台Compaction时，会将主键相同的多行进行sum求和，然后使用一行数据取而代之，从而大幅度降低存储空间占用，提升聚合计算性能。

- ClickHouse只在后台Compaction时才会进行数据的预先聚合，而compaction的执行时机无法预测，所以可能存在部分数据已经被预先聚合、部分数据尚未被聚合的情况。因此，在执行聚合计算时，SQL中仍需要使用GROUP BY子句。
- 在预先聚合时，ClickHouse会对主键列之外的其他所有列进行预聚合。如果这些列是可聚合的（比如数值类型），则直接sum；如果不可聚合（比如String类型），则随机选择一个值。
- 通常建议将SummingMergeTree与MergeTree配合使用，使用MergeTree来存储具体明细，使用SummingMergeTree来存储预先聚合的结果加速查询。



### AggregatingMergeTree

## Flink

优势：

- 整合了实时和离线计算为一套框架。
- 低延迟、高吞吐，保证正确性

spark streaming 高吞吐、正确性，但是延迟高。

storm 延迟低，但是性能和高并发下正确性不能保证。

运行时组件： 

**JobManager**

**TaskManager**：执行task。内存隔离，每一部分为一个Slot。注册到resourceManager。

**ResourceManager**：管理分配slot资源。

**Dispacher**： 分发任务，提供界面。

# Redis

## 单线程

Redis 中，单线程的性能瓶颈主要在网络IO操作上。也就是在读写网络 read/write 系统调用执行期间会占用大部分 CPU 时间。如果你要对一些大的键值对进行删除操作的话，在短时间内是删不完的，那么对于单线程来说就会阻塞后边的操作。

**Reactor模式**

- 传统阻塞IO模型客户端与服务端线程1:1分配，不利于进行扩展。
- 伪异步IO模型采用线程池方式，但是底层仍然使用同步阻塞方式，限制了最大连接数。
- Reactor 通过 I/O复用程序监控客户端请求事件，通过任务分派器进行分发。

**单线程时代**

- 基于 Reactor 单线程模式实现，通过IO多路复用程序接收到用户的请求后，全部推送到一个队列里，交给文件分派器进行处理。

**多线程时代**

- 单线程性能瓶颈主要在网络IO上。
- 将网络数据读写和协议解析通过多线程的方式来处理 ，**对于命令执行来说，仍然使用单线程操作。**